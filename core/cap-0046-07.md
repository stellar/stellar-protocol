```
CAP: 0046-07 (formerly 0055)
Title: Fee model in smart contracts
Working Group:
    Owner: MonsieurNicolas
    Authors: dmkozh
    Consulted:
Status: Draft
Created: 2022-06-03
Discussion: TBD
Protocol version: TBD
```

## Simple Summary

This CAP defines the mechanism used to determine fees when using smart contracts on the Stellar network.

## Working Group

TBD

## Motivation

With the introduction of smart contracts on the network, the existing fee model of the "classic" transaction system is too simplistic: it requires careful design of the code that runs "on chain" as to ensure that all operations have a similar cost and performance profile, which is not possible with arbitrary code running in contracts.

### Goals Alignment

Goals of the updated fee model are to:
* ensure fairness between users and use cases.
* promote scalable patterns on the network, doing more with the same amount of overall resources.
* ensure that the network operates in a sustainable way, network operators should be in control of their operating cost.

## Abstract

This CAP proposes various network level parameters (voted on by validators), and fee structure for the different kinds of resources involved on the network.

The fee structure is designed to discourage "spam" traffic and overall waste of infrastructure capacity.

## Specification

### XDR changes

The following network parameters are introduced (in some cases increments are used to mitigate for rounding errors):

```
// general “smart contract execution lane” settings
struct ContractExecutionLanesSettingsV0
{
    uint32 ledgerMaxTxCount; // maximum number of “smart” transactions per ledger
};

// "gas" aka "compute" settings
struct ContractGasNetworkSettingsV0
{
    int64 ledgerMaxGas; // maximum gas per ledger
    int64 txMaxGas; // maximum gas per transaction
    int64 minFeeRatePerGasIncrement; // minimum cost of GAS_INCREMENT=10k gas
};

// Ledger access settings
struct ContractLedgerCostNetworkSettingsV0
{
    uint32 ledgerMaxReadLedgerEntries;// maximum number of ledger entry read operations per ledger
    uint32 ledgerMaxReadBytes; // maximum number of bytes that can be read per ledger
    uint32 ledgerMaxWriteLedgerEntries;// maximum number of ledger entry write operations per ledger
    uint32 ledgerMaxWriteBytes; // maximum number of bytes that can be written per ledger

    uint32 txMaxReadLedgerEntries;// maximum number of ledger entry read operations per transaction
    uint32 txMaxReadBytes; // maximum number of bytes that can be read per transaction
    uint32 txMaxWriteLedgerEntries;// maximum number of ledger entry write operations per transaction
    uint32 txMaxWriteBytes; // maximum number of bytes that can be written per transaction


    int64 minFeeReadLedgerEntry; // minimum fee per ledger entry read
    int64 minFeeWriteLedgerEntry; // minimum fee per ledger entry write

    int64 minFeeRead1KB; // minimum fee for reading 1KB
    int64 minFeeWrite1KB; // minimum fee for writing 1KB

    int64 bucketListSizeBytes; // bucket list fees grow slowly up to that size
    int64 bucketListFeeRateLow; // fee rate in stroops when the bucket list is empty
    int64 bucketListFeeRateHigh; // fee rate in stroops when the bucket list reached bucketListSizeBytes
    uint32 bucketListGrowthFactor; // rate multiplier for any additional data passed the first bucketListSizeBytes
};

// historical data (pushed to core archives) settings
struct ContractHistoricalNetworkSettingsV0
{
    int64 minFeeHistorical1KB; // minimum fee for storing 1KB in archives
};

// Meta data (pushed to downstream systems) settings
struct ContractMetaDataNetworkSettingsV0
{
    uint32 txMaxExtendedMetaDataSizeBytes; // maximum size of extended meta data produced by a transaction
    int64 minFeeExtendedMetaData1KB; // minimum fee for generating 1KB of extended meta data
};

// Bandwidth related data settings
struct ContractBandwidthDataNetworkSettingsV0
{
    uint32 ledgerMaxPropagateSizeBytes; // maximum size in bytes to propagate per ledger
    uint32 txMaxSizeBytes; // maximum size in bytes for a transaction

    int64 minFeePropagateData1KB; // minimum fee for propagating 1KB of data
};

```

Additional changes at the Transaction/TransactionSet level:

```
// Transaction changes (actual diff TBD)

// int64 fee gets replaced by
   int64 gasFeeBid; // gas bid
   int64 ledgerDataAccessFeeBid; // bytes read & write bid
   int64 propagateFeeBid; // bytes flooded bid
   int64 flatResourcesFee; // other fees

// Additional properties:
   uint32 gas; // how much gas is needed for this tx

   uint32 readBytes; // how many bytes will be read by this tx
   uint32 writeBytes; // how many bytes will be written by this tx

   uint32 extendedMetaDataSizeBytes; // how many bytes can be added to the meta by this tx
   
// Additional property to support ephemeral payloads
    EphemeralPayload* ephemeralPayload;

struct EphemeralPayload
{
     Hash hash;
     uint32 size;
};

// TransactionEnvelope changes
    opaque<> ephemeralPayload; // used in conjunction with tx.ephemeralPayload

// SCP value: hash of GeneralizedTransactionSet before and after removing payload


// GeneralizedTransactionSet changes TBD, need a way to express different fee markets
```

Changes to ledger data:
```

TBD: `LedgerEntry` with expiration date

```

### Semantics

Validity constraints:
* source account must be able to pay for the total fee bid for that transaction.
* the number of smart contract transactions cannot exceed `ledgerMaxTxCount` per ledger

#### Resources with contention

For resources with contention, market dynamics are needed.

In this case, transactions get prioritized during flooding and inclusion on ledgers based on how they bid relative to other transactions.

The resources where we allow competition are:
* gas
* ledger data access (bytes transferred)
* network propagation (bandwidth)

#### Fee computation while applying transactions

As in classic, total fees are taken from the source account balance before applying transactions. Note that this is the observable behavior, implementations may decide to better stage updates.

At the end of the transaction execution, refund the source account for resources that are eligible for a refund (this refund is reflected under `txChangesAfter` in the meta).

Right now the following resources fall under this category:
  * historical data
  * extended meta data

Total fee is equal to:
total_fee =  gasFeeBid + ledgerDataAccessFeeBid + propagateFeeBid + flatResourcesFee;

__Open:__ it might be easier to make `tx.fee` the total fee, and derive `flatResourcesFee` from it, ie
`flatResourcesFee = total_fee - ( gasFeeBid + ledgerDataAccessFeeBid + propagateFeeBid )`.

#### Execution time

A transaction contains:
* how much "gas" they want to bid for. `uint32 Tx.gas`.
* the fee bid they're willing to pay for that capacity. `int64 Tx.gasFeeBid`.

`min_gas_fee(Tx) = round_up(Tx.gas*minFeeRatePerGasIncrement/GAS_INCREMENT)`

Validity constraints:
* per transaction
    * `Tx.gas <= txMaxGas`.
    * `Tx.gasFeeBid >= min_gas_fee(Tx)`.
* ledger wide (`GeneralizedTransactionSet`)
  * sum of all `tx.gas` <= `ledgerMaxGas`.

#### Ledger data

A transaction contains:
* the read `tx.LedgerFootprint.readOnly` and read/write `tx.LedgerFootprint.readWrite` sets (ledger keys).
* the maximum total amount of data `uint32 tx.readBytes` that gets read by `tx.LedgerFootprint.readOnly` and `tx.LedgerFootprint.readWrite`.
* the maximum total amount of data `uint32 tx.writeBytes` that can be written by `tx.LedgerFootprint.readWrite`.
* the fee bid for ledger data (both reads and writes) `int64 tx.ledgerDataAccessFeeBid`.

Ledger access contribution to `flatResourcesFee`:
```
ledgerDataAccess_flat_fee(tx) =
  (length(tx.LedgerFootprint.readOnly)+length(tx.LedgerFootprint.readWrite))*minFeeReadLedgerEntry + // cost of reading ledger entries
  length(tx.LedgerFootprint.readWrite)*minFeeWriteLedgerEntry // cost of writing ledger entries
```

Minimum bid:
```
min_LedgerDataAccess_fee(tx) =
  round_up(tx.readBytes * minFeeRead1KB / 1024) + // cost of processing reads
  round_up(wfee_rate(lcl.BucketListSize)* tx.writeBytes)) // cost of adding to the bucket list
```

With

```
wfee_rate(s) = (bucketListFeeRateHigh - bucketListFeeRateLow)*s/bucketListSizeBytes +
bucketListFeeRateLow +
(if s > bucketListSizeBytes,
    bucketListGrowthFactor*
    (bucketListFeeRateHigh - bucketListFeeRateLow)*
    (s-bucketListSizeBytes)/bucketListSizeBytes,
    0)
```

__Open:__ `wfee_rate` (and possibly `min_LedgerData_fee`) needs to be reconciled with "rent" (not finalized at the time of this writing) as "paying rent" is very similar to adding an entry to the ledger. The difference is that adding an entry to the ledger adds the entry to the "topmost" bucket, where as paying rent is adding an entry to a bucket while merging.

Validity constraints:
* per transaction
   * `length(tx.LedgerFootprint.readOnly) <= txMaxReadLedgerEntries`.
   * `tx.readBytes <= txMaxReadBytes`.
   * `length(tx.LedgerFootprint.readWrite) <= txMaxWriteLedgerEntries`.
   * `tx.writeBytes <= txMaxWriteBytes`.
* ledger wide (`GeneralizedTransactionSet`)
   * `sum(length(tx.LedgerFootprint.readOnly) + length(tx.LedgerFootprint.readWrite)) <= ledgerMaxReadLedgerEntries`.

#### Historical storage

`historical_flat_fee(txEnvelope) = round_up((size(txEnvelopeNoPayload)+TX_BASE_RESULT_SIZE) * minFeeHistorical1KB / 1024)`

Where `txEnvelopeNoPayload` is the envelope with the payload cleared out and `TX_BASE_RESULT_SIZE` is the size in bytes of the transaction result published to archives (not to be confused with the actual `TransactionResult` that is included in the meta).

Validity constraints:
_None_

#### Extended meta data

__open:__ we could consider removing `tx.extendedMetaDataSizeBytes` and instead just use `txMaxExtendedMetaDataSizeBytes`.
There are a couple potential problems:
* this may artifically increase the minimum account balance required to submit a transaction
* transactions may fail if the network votes to increase `txMaxExtendedMetaDataSizeBytes` (this problem may have to be solved in general anyways)

A transaction contains:
* `uint32 tx.extendedMetaDataSizeBytes` the maximum size of extended data produced by this transaction

`extendedMetaData_flat_fee(tx) = round_up(tx.extendedMetaDataSizeBytes * minFeeExtendedData1KB / 1024)`

Validity constraints:
* per transaction
  * `tx.extendedMetaDataSizeBytes <= txMaxExtendedMetaDataSizeBytes`

#### Bandwidth related

A transaction contains:
* implicitely, its impact in terms of bandwidth utilization, the size (in bytes) of the `TransactionEnvelope`
* the fee bid they're willing to pay for that capacity. `int64 Tx.propagateFeeBid`.


`min_NetworkData_fee(tx) = round_up(size(txEnvelope) * minFeePropagateData1KB / 1024)`

Validity constraints:
* per transaction
  * `size(txEnvelope) <= txMaxTxSizeBytes`
* ledger wide (inclusive of ephemeral data)
  * sum of all `size(txEnvelope)` <= `ledgerMaxPropagateSizeBytes`.

#### Flat resource fee

A transaction contains:
* `int64 tx.flatResourcesFee` fee shared by all “flat fee” resources

`tx.flatResourcesFee` must be greater than
`ledgerDataAccess_flat_fee(tx) + historical_flat_fee(txEnvelope) + extendedMetaData_flat_fee(tx)`

## "Fee bump" and failing transactions

__Open:__
The high number of settings involved in making a transaction succeed at runtime may cause additional usability issues.

Transactions may fail due to variance in behavior (similar to how footprints can change): underestimating any of the transaction level field may cause the transaction to be included in a ledger, but fail later on (causing the sequence number to be consumed and fees burned).

There might be a need for a "fee bump" wrapper transaction of sorts that takes the burden in case of failure, and that allows to override the problematic fields (including footprints and any limit and fee related fields).

Unlike "fee bump", the outer "bump" transaction would have its own sequence number/fees.


## Design Rationale

### Fee estimation

This proposal relies heavily on the existence of a "preflight" mechanism to determine all parameters needed to compute minimum fees.

Additional logic (not covered in this CAP), will be needed to determine the market rate of resources based for example on historical data (see below).


### Resources

Fees are used to ensure fair and balanced utilization of resources.

For each resource type, we're assuming a model where we can define:
* the maximum resource consumption for a transaction, as to protect the network.
* a minimum "floor" price for a given transaction, as to ensure that there are no broken markets
* additional constraints may include
    * a "ledger wide" maximum as to protect the network and downstream systems when producing blocks.
    * "execution lane" maximum, as to ensure that execution lanes (executed in parallel), are balanced. This CAP does not attempt to define actual semantics or fee models related to parallel execution, and is mentioned here for context.

We’re also assuming that resource allocation is done independently of “classic” transactions (ie: the amount of resources allocated to smart contract execution is independent of other traffic). This points to “smart contract transactions” being managed as their own “phase” (in `GeneralizedTransactionSet` terminology) and having its own dedicated capacity expressed in terms of transactions (`ledgerMaxTxCount`).

The only reason for having "minimum fees" (on top of "on chain market dynamics"), is to combat "spam" transactions and ensure that there is no strange incentive to perform certain operations on chain instead of performing them on other systems with worse properties (like centralized cloud infrastructure).

Validators are expected to vote regularly (once a quarter for example) to ensure that fees are set correctly for the broader ecosystem. The exact way minimum fees are established is outside the scope of this document.

#### Compute

[CAP-0046: WebAssembly Smart Contract Runtime Environment](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0046-01.md) introduces the notion of "gas". In the context of this CAP, the only thing that matters is that "gas" represents an arbitrary base unit for "execution time".

As a consequence, the "goal" for validators is to construct a `GeneralizedTransactionSet` that uses up to `lcl.ContractNetworkSettingsV0.ledgerMaxGas`.

#### Ledger data

##### Read traffic

Reads are logically performed *before* transaction execution.

When performing reads of a ledger entry:
* The ledger entry needs to be located via some index in the ledger and the entry loaded. Depending on the underlying database technology, this translates to at least 1 disk operation.
* The bucket entry needs to be xdr decoded.

The resources to allocate in this context are therefore:
* a maximum number of ledger entry read operations in a ledger `ledgerMaxReadLedgerEntries`.
* a maximum number of bytes that can be read in a ledger `ledgerMaxReadBytes`.

The cost of a "ledger entry read" is fairly open ended, and depends on many variables. In this proposal, we give it a "base cost" for simplicity even if it translates to multiple disk operations (which is typically the case when using B-Trees for example, or if the ledger entry is retrieved by lookup over multiple buckets).

That "base cost" is defined by validators as `minFeeReadLedgerEntry`. This proposal does not let transactions compete directly on the number of ledger entry read operations, therefore the cost of a read operation is `minFeeReadLedgerEntry` (validators must still construct transaction sets that keep the number of reads below a maximum).

Market dynamics are limited to the number of bytes (see below).

Transactions contain the total number of bytes that they will read from the bucket list as well at a fee bid for reading those bytes.

The number of bytes read corresponds to the size of the latest `BucketEntry` for that ledger entry (and does not take into account the possibility that an implementation may read stale entries in buckets or may have to read other entries from a bucket).

The minimum fee bid is determined based on the rate `minFeeRead1KB` expressed for reading 1 KB (1024 bytes) worth of data.

As transactions compete for the total read capacity `ledgerMaxReadBytes` for a given ledger, the effective fee goes up.


##### Write traffic and ledger size

Writes are performed *after* transaction execution, and are blocking the actual closing of a ledger.

When writing a ledger entry:
* The bucket entry is marshaled to binary.
* The bucket entry is appended to the topmost bucket serially.
* The bucket entry is read, hashed and written back with every level merge operation.

In this proposal, we're modeling "worst case": a bucket entry gets added to the bucket list and has to travel all the way to the bottom bucket, contributing as many bytes as the bucket entry itself.

In that case, the overhead is dominated by the size of buckets and bucket entries, and the number of bucket entries is not really a factor when merging.

Consequently, we can model the cost of a write as an append to the overall bucket list and charge a "base rate" for adding a bucket entry.

For allocating ledger entry writes, the model is analogous to "reads": a ledger is constructed as to not exceed `ledgerMaxWriteLedgerEntry` writes and each write contributes `minFeeWriteLedgerEntry` to the overall fee for that transaction (no market dynamics here).

As for "bytes written", the model that was chosen is:
* use the total bucket list size as the main resource to track.
* a cost function, allows to price the cost of expanding ledger size.
* ledger size, and therefore price of storage, goes down as bucket entries get merged/deleted.

The cost function that was selected is similar to what was proposed in Ethereum's [make EIP 1559 more like an AMM curve](https://ethresear.ch/t/make-eip-1559-more-like-an-amm-curve/9082).

The main point being that the fee for adding `b` bytes to a bucket list of size `s` is calculated as `fee(b,s) = lfee(s + b) - lfee(s)`, where `lfee` is the "total cost to build a bucket list of a given size".
When designing for specific properties of that function, it's useful to see the "fee rate": `fee_rate(s) = lim b->0, fee(b, s)/ b = (lfee(s+b) - lfee(b))/b`, is the derivative of `lfee`, ie `fee_rate(s) = lfee'(s)`.

Properties that we're looking for:
* validators should be able to pick parameters such that total bucket list size can grow to size `M_base` (that is deemed manageable by the ecosystem), but puts up a lot of resistance to grow to size `M_base+M_buffer` and beyond.
* `fee_rate(s)` should provide enough feedback for users and use cases to self-correct. It would not be desirable at the extreme to have very low fees up to `M_base` and suddenly "hit a wall" where fees shoot up to extremely high numbers after that.

Given those, the choice for `fee_rate` is constructed as the superposition of the following 2 functions (integrating yields the respective `lfee` component):
* `(feeRateM - minFeeRate)*s/M_base + minFeeRate` --> `(feeRateM - minFeeRate)*s^2/(2*M_base) + minFeeRate*s`
* `if s > M_base, exp(K*(s-M_base)/B_buffer)` --> `exp(K*(s-M_base)/B_buffer)*B_buffer/K`

Where `minFeeRate` and `feeRateM` are the fee rate at size 0 and `M_base` respectively.

Which together yields:

`lfee(s) = (feeRateM - minFeeRate)*s^2/(2*M_base) + minFeeRate*s + (if s > M_base, exp(K*(s-M_base)/B_buffer), 0)`.

With `K` picked such that `fee(1, M_base+M_buffer)` is orders of magnitude larger than what the market would be willing to pay.

We simplify those functions further by charging fees linearly to the number of bytes within a ledger (see rationale below).

As a consequence the final formula looks like this:

`fee(b) = round_up(b*fee_rate(s))`

With
`fee_rate(s) = (feeRateM - minFeeRate)*s/M_base + minFeeRate + (if s > M_base, exp(K*(s-M_base)/B_buffer), 0)`

We can simplify this even further by replacing the exponential component by a steep linear slope that causes fees to be "extremely high" at `M_buffer`.

##### Putting it together

"read/write" operations need to first read data before writing it. The amount of data written back can be larger or smaller than what was read, as consequence:
* The number of ledger entry reads is the size of ledger entries referenced in ledger footprints (both read and read/write).
* The number of bytes to read is the size of bucket entries from both the read and read/write footprints.
* The number of bytes to write is the number of bytes associated with bucket entries referenced by the readWrite footprint.
* The number of ledger entry to write is the size of the read/write footprint.

##### Effective fee and flooding

Having the fee model depend on ledger size creates some complication when trying to reason about multiple transactions getting applied: a naive solution would just try to follow the price curve exactly, causing fees to evolve on a per transaction basis.
This would create incentives to front-run transactions within the same transaction set, and would also make it hard to decide if a transaction should get flooded.

In the context of this proposal, we make the following observation: assuming that validators pick a small upper bound for the total number of bytes that can be added to the bucket list per ledger relative to the bucket list size, we can then assume that the price of storage varies marginally per ledger (ie the price paid by the first transaction is not that different from the last transaction in a ledger), and that the reference price still "resets" to the proper price every ledger (as it's based on the size of the bucket list).

As a consequence, we can just price transactions independently, based on the bucket list from the last closed ledger, and allocation within a transaction (for multiple bytes) is a flat rate as well.

Flooding transactions for the next ledger in that context is straightforward as the only factor to take into account is bucket list size (determined based on the last closed ledger).

Note that transactions can still be invalidated more than a ledger in the future, as a consequence validators may apply a certain level of "padding" when computing the minimum fee required before flooding those transactions.

##### Ledger size reduction

So far we've established a model for deriving fees based on the bucket list size, but there needs to be a mechanism to ensure that the cost of storage does not grow indefinitely, hurting usability of the network.

Core ideas and principles:
* Ledger space is a shared public resource, policies should be set to ensure fair use.
* cost of using ledger space should converge towards market rate over time
   * in particular creating spam ledger entries should cost market rate over the long term.
* abandoned entries should not cost anything to network participants over the long term.

This proposal therefore depends on a solution with the following high level properties:
* ledger entries have to periodically pay for "rent", where the rent amount is adjusted on a per period basis (as to approximate "market rate")
* ledger entries that do not want to pay for rent anymore should be purged from the ledger, freeing up space for other entries (and lowering the overall price of storage)
    * purged entries may be recoverable by relying on external recovery nodes that can reconstruct proofs that validators can verify.

#### Historical storage

Historical storage corresponds to data that needs to be persisted by full validators outside of the bucket list.

This includes transactions and their result.

As the data is stored only once but for "eternity", it has to be priced accordingly (at a minimum, this data has to be made available as to allow validators to catch up to the network).

The model retained in the context of this CAP is to just have the validators set a flat rate per byte for this kind of data (updated on a regular basis as to track cost of storage over time).

##### Transaction Result

In order to reduce the base cost of transactions, the "result" published to archive is fixed size and the actual detailed transaction result is now emitted in the meta. See [CAP-0046: Smart Contract Events](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0046-08.md) for more details.

#### Extended meta data

__Open:__ this resource would benefit from refunds (as there is no "per ledger" limit).

Extended meta data here refers to parts of the meta data (produced when closing ledgers) that are not related to ledger changes:
* Smart contracts generate "events"
* `TransactionResult`

See [CAP-0046: Smart Contract Events](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0046-08.md) for more details.

Fees are needed to control for the overhead in those systems.

The model retained in this CAP is a flat rate per byte model for simplicity. It is expected that this fee would be orders of magnitude smaller than what is needed to persist data on chain.


#### Bandwidth

Transactions need to be propagated to peers on the network.

At the networking layer, transactions compete for bandwidth on a per ledger basis (`ledgerMaxPropagateSizeBytes`).
A minimum is also defined as spam countermeasure.

Note that validators may apply additional market dynamics due to implementation constraints, especially when trying to balance propagating large transactions vs smaller ones. See [CAP-0042: Multi-Part Transaction Sets](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0042.md).

##### Ephemeral payload

Transaction may contain an `ephemeralPayload` (Hash + size), that gets cleared before applying transactions (used in the context of proofs of availability).

Further reading: [blob transactions in Ethereum](https://notes.ethereum.org/@vbuterin/blob_transactions).

#### Base rates are independent of transaction ordering

The "base rate" for resources is picked to be the same for all transactions in a given fee group (see CAP-0042 for definition on “groups”) within a ledger.

This avoids creating incentives for "front running" transactions within a ledger just to get a better rate.

#### Refunds on “flat rate” resources

Some resources are priced determined on a per ledger basis, independently of transaction set composition.

For such resources, a transaction gets charged the “worst case” utilization at the beginning of the transaction execution, and gets refunded based on actual usage at the end of the execution.

#### No refund for unused capacity on market based resources

If a transaction declares that it wants to use up to X units of a given resource, nominators assemble a transaction set with that information, potentially excluding other transactions because of this.

As a consequence, there should not be any refund for unused capacity. Specifically, if a resource was priced at a given rate by validators, the fee charged will be for the entire capacity (note that this still lets validators provide discounts on the rate).

#### Multidimensional vs uniform fees


__Open:__ this choice depends on how many markets we really have. This proposal has 3 dimensions: gas, number of bytes read/written and network bandwidth. We could instead predefine markets and let market price be determined in each of those markets, this would allow to reduce the number of “bids” to a single value. For example, there could be the following markets: <compute, low read and write>, <low compute, high read and write>. As the “on the wire” savings are not that high (8 bytes saving), we’ve decided to leave bids separate at this time.

As transactions are competing for some resources, there needs to be a way to prioritize transactions between each other.

Note that we’re excluding “flat rate” resources where there is no competition from this section.

There are two ways to do it:
* have a separate market for each dimension. Transactions need to explicitly bid on each dimension.
   * This allows accurate price discovery for all resources. For example, if there is a lot of contention on "gas", this allows to discover the price of a unit of gas.
   * Relative priority between transactions is flexible, this is good (more room for innovation by nominators) and bad (harder for clients to know what to do to “get ahead”).
* transactions just specify a "fee bid" for multiple dimensions at once (potentially all markets at once)
   * there needs to be a function that computes the "minimum fee" for a given transaction, mixing all dimensions somehow (polynomial of sorts for example).
   * comparing transactions can be done by comparing the ratio between the fee bid and the minimum fee, which is simple.
   * There is no price discovery of individual dimensions as people automatically bid more on all dimensions at once. That said, nominators can just pick "market prices" for each dimension that fits recent network conditions.

Both solutions require nominators to price resources (in much the same way that CAP-0042 allows nominators to price operations in the classic protocol).

The bidding is more complicated with the first approach. In order to come up with a reasonable bid, clients need not only to have 'market prices' for every resource, but also need to take into account the comparison algorithm used during transaction set building. For example, validators may consider ordering transactions by a tuple of bid-to-min-fee ratios for every resource (e.g. (gas, IO, bandwidth)) and in order to prevent abuse of the fixed order, they would dynamically come up with that order depending on the current contents of the transaction queue. It's not obvious how to bid optimally for such an algorithm, as every ledger priorities might change several times.

For the second approach the bidding is comparable with the classic transactions: there is just a single 'market rate' for the smart contract transactions, that can be both used as a part of the bidding strategy and for comparison. The downside is that the users are bound to overbid for some resources. This can be alleviated to some degree by applying per-resource surge pricing, so if there is no contention for some resource, then the overbidding wouldn't happen either.


Related work:
  * Ethereum [Multidimensional EIP-1559](https://ethresear.ch/t/multidimensional-eip-1559/11651).

#### Deriving the base fees

No matter the bidding approach, the network configuration has to have minimum fees per-resource defined. While this is not strictly a part of the protocol, this is an important question to answer, as it's hard to argue if an arbitrary set of parameters is fair or not. The proposed procedure is as following:

* Define the maximum base fee of the transaction (`maximumTotalBaseFee`) that maxes out on all the 'market' resources (e.g. gas fee would be `txMaxGas * minFeeRatePerGasIncrement / GAS_INCREMENT` etc.). This could be defined as an additional network parameter or as a function of all the configs described in this CAP. The fee can be calibrated relatively fairly via establishing a baseline for a smart operation using a similar classic operation (e.g. a payment using the Stellar Asset Contract) and scaling it proportionally to the maximum per-transaction capacity. For example, if we can fit a contract equivalent of 50 payments into a single transaction, then the maximum contract base fee will be at least 50 times the classic base fee. Additional multiplier can be applied to account for the fact that smart contract transactions still need to do some additional work compared to the classic operations.

* Distribute the maximum base fee between the per-resource fees proportionally to historical contention during the adjustment period. For example, if 90% of the time contention was due to gas only, 10% of the time due to network bandwidth and there was no contention on ledger data access, then we would set maximum gas base fee to `0.9 * maximumTotalBaseFee - reserveFee / 2`, maximum network bandwidth fee to `0.1 * maximumTotalBaseFee - reserveFee / 2` and ledger data access to `reserveFee` (where `reserveFee` is another network parameter defined as e.g. 1% of `maximumTotalBaseFee`).

This procedure ensures that the base resource fees reflect the network patterns. It also positively impacts the uniform fee rate approach, as overbidding on a low-contention resource would still result in low fees even in an unlucky situation where the surge pricing triggers for a resource that rarely has any contention.

## Protocol Upgrade Transition
None, this fee model will only apply to smart contract transactions.

A subsequent CAP may update the fee model for the existing classic transaction subsystem as to be more consistent with this CAP.

### Resource Utilization

## Security Concerns


## Test Cases
## Implementation



