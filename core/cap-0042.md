## Preamble

```
CAP: 0042
Title: Multi-Part Transaction Sets
Working Group:
    Owner: nicolas@stellar.org
    Authors: TBD
    Consulted: TBD
Status: Draft
Created: 2021-11-29
Discussion: TBD
Protocol version: TBD
```

## Simple Summary

This CAP adds additional structure to transaction sets such that transaction sets can be expressed in terms of groups of transaction sets as to faciliate implementing per group policies such as order book aware surge pricing.

## Working Group

TBD

## Motivation

Right now, there is no mechanism that makes it possible to implement different fee structures based on transaction set composition; as a consequence, transaction set composition can sometimes be heavily biased towards undesirable behaviors such as spikes of arbitrage trades that eventually fail.

This CAP aims to correct this by isolating subsets of transactions that can compete on fees without causing overall fees to increase. At the same time, it makes it possible to expand policies to other dimensions in the future.

### Goals Alignment

The Stellar network aims to give equitable access to the global financial infrastructure, in particular the network should not benefit a minority of participants at the expense of others.

This CAP aims at restoring balance between use cases on the network.

## Abstract

Right now transaction fees are computed for a given ledger based on [CAP-0005 Throttling and transaction pricing improvements](CAP-0005.md).

CAP-005 defines:
* How a transaction set (to be applied for the next ledger) gets constructed from an arbitrary number of candidate transactions as to enforce the policy that puts a bound on the number of operations present in any given ledger.
* The base fee to use when applying a transaction set

This CAP generalizes the above in the following way:
* It allows to describe transaction sets in terms of sets of transaction subsets
* Each subset gets constructed in a similar way to CAP-005, following additional policies
* Each subset gets its own base fee

Note that this CAP does not modify how transactions gets applied (ie: the apply order) other than fee computation.

## Specification

### XDR Changes

This patch of XDR changes is based on the XDR files in commit (`394b9413180969e2035e19742194d9c04c5bf5d9`) of stellar-core.
```diff mddiffcheck.base=394b9413180969e2035e19742194d9c04c5bf5d9
diff --git a/src/xdr/Stellar-ledger.x b/src/xdr/Stellar-ledger.x
index 84b84cbf7..c9d7f461f 100644
--- a/src/xdr/Stellar-ledger.x
+++ b/src/xdr/Stellar-ledger.x
@@ -176,14 +176,56 @@ case METAENTRY:
     BucketMetadata metaEntry;
 };
 
-// Transaction sets are the unit used by SCP to decide on transitions
-// between ledgers
+enum TxSetPropertyType
+{
+  TXSET_PROP_BFEE = 0,
+  TXSET_PROP_GROUP_BFEE = 1
+};
+
+// Subsets are expressed in terms of indices
+// based on the main transaction set.
+// Indices must be in strictly ascending order.
+// a subset cannot be empty
+typedef int TxIndices<>;
+
+union TxSetProperty switch (TxSetPropertyType t)
+{
+case TXSET_PROP_BFEE:
+  // base fee to use by default (overrides `ledgerHeader.baseFee`)
+  int64 txSetDefaultBaseFee;
+case TXSET_PROP_GROUP_BFEE:
+  // base fee to use for a group of transactions
+  struct
+  {
+    int64 baseFee;
+    TxIndices txIndices;
+  } txSetGroupBaseFee;
+};
+
 struct TransactionSet
 {
     Hash previousLedgerHash;
     TransactionEnvelope txs<>;
 };
 
+struct TransactionSetV1
+{
+    Hash previousLedgerHash;
+    TransactionEnvelope txs<>; // sorted in hash order (like a `TransactionSet`)
+    TransactionSubSet subsets<>;
+};
+
+// Transaction sets are the unit used by SCP to decide on transitions
+// between ledgers
+
+union GeneralizedTransactionSet switch (int v)
+{
+case 0:
+    TransactionSet v0TxSet;
+case 1:
+    TransactionSetV1 v1TxSet;
+};
+
 struct TransactionResultPair
 {
     Hash transactionHash;
@@ -203,11 +245,13 @@ struct TransactionHistoryEntry
     uint32 ledgerSeq;
     TransactionSet txSet;
 
-    // reserved for future use
+    // when v != 0, txSet must be empty
     union switch (int v)
     {
     case 0:
         void;
+    case 1:
+        GeneralizedTransactionSet txGeneralizedSet;
     }
     ext;
 };
@@ -358,9 +402,30 @@ struct LedgerCloseMetaV0
     SCPHistoryEntry scpInfo<>;
 };
 
+struct LedgerCloseMetaV1
+{
+    LedgerHeaderHistoryEntry ledgerHeader;
+    // NB: txSet is sorted in "Hash order"
+    GeneralizedTransactionSet txSet;
+
+    // NB: transactions are sorted in apply order here
+    // fees for all transactions are processed first
+    // followed by applying transactions
+    TransactionResultMeta txProcessing<>;
+
+    // upgrades are applied last
+    UpgradeEntryMeta upgradesProcessing<>;
+
+    // other misc information attached to the ledger close
+    SCPHistoryEntry scpInfo<>;
+};
+
 union LedgerCloseMeta switch (int v)
 {
 case 0:
     LedgerCloseMetaV0 v0;
+case 0:
+    LedgerCloseMetaV1 v1;
 };
-}
+
+} // namespace stellar
```

### Semantics

#### Consensus value

SCP messages and ledger header reference transaction sets by hash. Consequently, the preimage supplied can transparently be migrated to `GeneralizedTransactionSet` when voting for a transaction set that can be applied using the version of the protocol with this CAP.

In summary: if `lcl.ledgerHeader.version` is less than `P` (version this CAP takes effect), the preimage must be a `TransactionSet`, otherwise it must be a `GeneralizedTransactionSet`.

#### Value Validation

A `v1TxSet` is validated using the following rules:
* `previousLedgerHash` is equal to the hash of the previous ledger
* `txs` is a valid transaction set (validated like a `TransactionSet.txs`)
* `properties`
  *  `TXSET_PROP_GROUP_BFEE` do not overlap (ie: `txIndices` are disjoint)
  *  `TXSET_PROP_BFEE` present at most once; `txSetDefaultBaseFee` is strictly greater than `ledgerHeader.baseFee` (surge pricing is active)

The effective default base fee for that ledger is therefore equal to `txSetDefaultBaseFee` (if set) or `ledgerHeader.baseFee`.

Each `TXSET_PROP_GROUP_BFEE` subset is validated with:
* `txIndices` is not empty
* transactions within `txIndices`:
  * are sorted in strictly ascending order
  * must reference valid transactions from `txs` (ie, each index must be within bounds)
* `basefee` must be strictly greater than the effective default base fee for that ledger.
* `basefee` must be less (or equal) than the smallest base fee bid from transactions included in that subset (ie: transactions can pay for that `baseFee`).

#### Effective fee computation

The effective base fee for a given transaction is computed in the following way:
  * If the transaction is in a `txSetGroupBaseFee` subset, the base fee is defined by that subset's `basefee`.
  * Otherwise, its base fee is `txSetDefaultBaseFee` if set,
  * Otherwise, its base fee is `ledgerHeader.baseFee`

Note that this is not ambigiuous as a transaction can only be present in at most one subset by construction.

#### Candidate value generation

Just like today, this CAP does not specify the exact algorithm used to produce a valid value as to make it easier for implementations to compete on the quality of transaction sets.

A potential algorithm that could be used in the initial rollout of this CAP can be something like:

1. build a "surge pricing order iterator" (similar to CAP-0005), that feeds transactions in decreasing priority order
2. Initialize `tradingTxGroup={txs: [], ops: 0, baseFee:0}`
3. iterate over transactions in that order and:
   1. if the transaction would cause the candidate set to have more than `ledgerHeader.maxTxSetSize`
        * Surge pricing is in effect, add a `TXSET_PROP_BFEE` property with `txSetDefaultBaseFee` set to the base fee of the currently rejected transaction
        * Stop adding transactions to the set
   2. if the transaction contains any operation that could cross an offer (PathPayment and ManageOffer variants), attempt to add it to the `tradingTxGroup` list:
       * if `tradingTxGroup.baseFee != 0`:
         *  (it's already full)
         *  skip that transaction
       * else:
         * `K=max(101, ledgerHeader.maxTxSetSize/10)` # group limit
         * if `tradingTxGroup.ops + nb_ops(tx) <= K`:
           * `tradingTxGroup.txs += tx`
           * `tradingTxGroup.ops += nb_ops(tx)`
         * else:
           * surge pricing is in effect for that group
           * `tradingTxGroup.baseFee = baseFee(tx)`
           * skip that transaction
       * if the transaction was skipped, skip all remaining transactions from that source account (as subsequent sequence numbers would be invalid) ; 
       * otherwise add it to the candidate set
4. Sort the transaction set in "hash order"
5. If `tradingTxGroup.base_fee != 0`:
   * add a `TXSET_PROP_GROUP_BFEE` property derived from `tradingTxGroup`

#### Nomination value comparison

The order used by the nomination protocol's combine candidate function needs to be modified to support properties.

Values are sorted in lexicographic order by:
* number of operations (as to favor network throughput) _unchanged_,
* total fees that the transaction set will collect (as to maximize quality of transaction sets) _unchanged_,
* size in bytes of properties, in decreassing order (to promote deduping),
* hash as a tie-breaker _unchanged_

#### Implications on transaction flooding strategy

Not technically part of the protocol but described here for completeness.

Today's implementation uses "surge pricing order" to prioritize which transaction to flood next. This does not need to change.

The change that can be done at the transaction queue level is to expand the policy as to support something similar to "step 2" above under [Candidate Value Generation](#candidate-value-generation) :
today's transaction queue policy only allows nodes to accumulate up to a maximum number operations in memory (by applying a multiplier on `ledgerHeader.maxTxSetSize`). The policy can be expanded to also track per order book counters, and not accept transactions that would cause to go over that limit (in this case, we would probably just the raw policy number and not even allow to accumulate more than what would be included in a ledger).

## Design Rationale

The proposal tries to limit to a minimum the number of things actually enforced at the protocol layer, leaving the door open to more flexibility at the node level.

In turn, this flexibility should allow for faster iteration without having to take a dependency on network wide protocol changes.

The choice of using "indices" to represent subsets (as opposed to embedding transactions directly), leaves some flexibility on the use of subsets in the future that "tag" transactions for purpose other than fee processing. Depending on those use cases, those new subset types may or may not overlap with subsets introduced in this CAP.

## Protocol Upgrade Transition

As soon as this CAP becomes active, nodes will produce new SCP values stored in the ledger header.

### Backwards Incompatibilities

This CAP does not change transaction semantics, impact on the ecosystem should be minimal.
Systems that try to compute transaction fees that are close to market rate will have to be adjusted as "ledger capacity" would only be losely related to "local surge pricing".
Users that just bid what they're willing to spend on fees, will not be effected.

### Resource Utilization

This change will require a small increase in CPU and memory utilization which should easily be recovered by the expected decrease in failed transactions.

## Security Concerns

The changes on the security front are minimal as transaction semantics are not changed.

This CAP gives more control to validators when it comes to fees: a validator could isolate an arbitrary subset of transactions as to force higher fees on them.

This should not be a problem in practice:
* transactions will never be charged more than their maximum bid, and people tend to put small multipliers on top of market rate (fees remain low).
* as validators do not receive fees from transactions processing, there is little incentive for a validator to do this.
* if validators target certain transactions like this, as values are signed by the validator that produced the value, the faulty validator will accrue negative reputation on the network.
 
## Future work

This CAP leaves the door open to how properties and fee groups can be used.

Here are a few examples:
* fee groups can be used to prioritize based on dimensions other than order book as to rebalance use cases, for example based on the expected number of changes to the ledger.
* properties could be used to alter the "apply order" policy: some subsets may get applied before others, or (groups of) subsets could be applied in some interleaved way.
* Subsets could also be a building block for "parallel execution": subsets could be organized into "independent units" (that can be applied in parallel in some way).
* Properties could add random numbers/seeds/parameters to update certain ledger entries (like oracles)
* Properties related to which network partition this transaction set originated from (nominators could flood differently based on that)

## Test Cases

TBD

## Implementation

TBD
